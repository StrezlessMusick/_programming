todo
разобраться с функциями работы с многобайтовыми символами
	и как они сюда впишутся
переписать классификацию
переписать -итого-


философия библиотеки ввода-вывода, удобной для парсинга
и унифицирующей интерфейс потоков и строк в стиле СТЛ
------
предположим вам надо разобрать(распарсить) текст, написанный на языке произвольной сложности (например таком как си++)
ну вы наверное начнете с описания языка
скорее всего опишите его нотацией Бекуса-Наура (на сколько это возможно)

и, как один из вариантов, отдадите эту нотацию в yacc,
а потом будете прикручивать обработку распарсенного к тому, что выплюнул yacc

я же предлагаю писать код на си++ (практически) взаимно-однозначно соответствующий нотации бекуса-наура (такой, что 1 изменение в нотации приводит к 1 изменению в коде)

предположим, что все, что мы собираемся парсить, скопировано в строку

каждому предложению НБН будет соответствовать функция:
берущая указатель на то место, откуда требуется распасить данное предложение, 	берет его по указателю
берет указатели на переменные, которые надо вернуть
/*
можно брать указатель на это место и все остальное не по указателям, а по ссылкам, но
я противник неконстантных ссылок, 
(потому что это выглядит как передача по значению, и не хочется каждую секунду задумываться: это по значению или по ссылке?)
однако можно заметить, что 
указатель на char можно преобразовать в указатель на const char
а указатель на указатель на char нельзя преобразовать в указатель на указатель на const char
! надо проверить, что будет со ссылками здесь
*/
и возвращает (через свое имя) bool: удалось ли распарсить то что требовалось
если распарсить удалось
	указатель по строке оказывается там, где закончило парситься выражение
	и вызывающей данную функцию функции, чтобы разобрать следующее предложение, достаточно передать указатель на этот указатель в следующую функцию (соответствующую следующему предложению)
если не удалось
	указатель по строке окажется в произвольном месте
	и вызывающая данную функцию функция может
		восстановить (предварительно сохраненный) указатель по строке на то место, откуда он вызывал данную функцию, и попытаться с этого же места разобрать другое выражение при помощи другой функции
		или закончить разбор с неудачным результатом
получается для предложения НБН expr::=expr1 expr2 функция
bool read_expr(char ** pp, ....)
{
	if(!read_expr1(pp, ....))
		return false;
	if(!read_expr2(pp, ....))
		return false;
	/*обработку возвращаемых значений добавить по вкусу*/
	return true;
}
а для предложения НБН expr::=expr1 | expr2 функция
bool read_expr(char ** pp, ....)
{
	char * p=*pp;
	if(read_expr1(pp, ....))
		return true;
	else if(read_expr2((*pp=p, pp), ....))
		return true;
	else return false;
	/*обработку возвращаемых значений добавить по вкусу*/
}

/*
формат функций я вначале придумал следующуй:
	функции берут все тот же указатель на указатель
		и все
	а возвращают разобранное значение (через свое имя) (если их несколько - структурой)
	а при неудачном прочтении кидают исключение
но потом от него отказался, т.к.:
	видимо, Страуструп сделал намеренно конструкцию
	try{
	}
	catch(....)
	{
	}
	с обязательными фигурными скобками
	и тогда вид функций, описанных выше, становится отвратительным
Видимо, Страуструп это сделал специально, т.к. исключения надо кидать в исключительных случаях, а неудачное прочтение какого-то выражения встречается сплошь и рядом (и не является исключительным случаем).
*/

это чем-то напоминает функцию ungetc, работающую всего на 1 символ назад
---------------------

теперь мы таким же образом хотим парсить не только строки но и непосредственно файлы, без копирования в строку

с файлами на диске это делать действительно просто, т.к. для них (в отличие от stdin) существуют функции fgetpos, fsetpos, fseek, ftell

и теперь попытаемся унифицировать интерфейс строк и потоков

ну, си-строки завершаются 0м символом. Конечно есть тип string, и для чтения его можно передавать в функции по константной ссылке, но если функция изменять строку не планирует, как ни крути, быстрее будет передавать const char *.
/*
тип string - это контейнер, и если мы планируем в функции изменять строку, то нам понадобится или string, или char * и размер выделенной под строку памяти, или char * и глобальный размер всех буферов, выделенных под строки, если конечно все буфера для строк имеют одинаковый размер, что бывает довольно редко
(случай когда заранее известно, что функция не увеличит резмер строки, исключаем из рассмотрения, как слижком частный)
таким образом, перед передачей строки в функцию надо определиться, будет ли функция только читать строку, или же она будет туда еще и писать
и на низком уровне операции со строками надо рассматривать именно в этих понятих (читать и писать); конкатенация - более высокоуровневая операция (представимая через читать-писать)
*/

а потоки никто заранее не читает, чтобы знать, сколько символов осталось до конца файла (и размер файла заранее тоже никто не спрашивает), а использует EOF==(ch=getc(stream)) или просто bool eof(stream)

формат перебора в классическлм стиле СТЛ for(iterator it=x.begin(); it!=x.end(); ++it) не подходит
решение следующее:
определяем для каждого типа итераторов перегруженную функцию bool atend(it)
и формат перебора становится следующим for(iterator it=x.begin(); !atend(it); ++it)
/*
inline
bool atend(const char * p)
{	return !*p;	}//0 - true; else - false
кстати помним, что все алгоритмы умеют работать с обычными указателями и массивами
*/
для записи по аналогии можно определить void putend(it)

про input & output итераторы я скажу, что это жалкие костыли, бесполезные для парсинга
-------------------
теперь определимся с внутренним устройством потоков

если это файл, то можно использовать функции fgetpos, fsetpos, fseek, ftell
а если это stdin или что-нибудь связанное с сетью?
наложим условие на файл, что его нужно прочесть за один проход
!заметим, что при парсинге все указатели движутся только вправо
+, само собой, их можно копировать

решение следующее:
список буферов фиксированного размера**
как только какой-нибудь итератор выходит за пределы самого правого буфера
в список добавляется новый буфер, и заполняется непосредственно из файла блоком данных
но постепенно так в память загрузится весь файл, а мы этого не хотим
!сделаем так, чтоб удалялись все буфера, находящиеся левее буфера на котором находится самый левый (отстающий) итератор
но мы не будем каждому буферу сопоставлять список итераторов, находящихся на нем, а будем сопоставлять всего лишь их количество (подсчет ссылок)
как только какой-нибудь буфер узнает, что на нем осталось 0 итераторов и что он самый левый, тогда удаляется он и все соседние буфера правее него, на которых тоже 0 итераторов

/*
про терминологию:
Я НЕ ЗНАЮ, но может имеет смысл 
во всем моем повествовании переименовать:
буфера в блоки
потоки в буфера
файлы в потоки

правда тогда будет библиотека не строк и потоков (STRing and STReam)
а строк и буферов 
*/

/*
сложность и эффективность операций:

каждый итератор по файлу будет содержать:
указатель на позицию в буфере
указатель на конец буфера
указатель на всю структуру буфера

при разыменовании итератора он возвращает ссылку на позицию в буфере
при перемещении (а это возможно только вправо) он проверяет границу буфера
 /*
например в декуе происходит тоже самое, и никто же не жалуется =)
и потом, это все-таки файл, если хочется чего-то сверх быстрого - 
лучше его полностью загрузить в строку (если он конечно поместиться)
 */
если он дошел до границы буфера
если следующий буфер отсутствует - он загружается, с количеством итераторов=0
	если этот буфер был последним во всем файле - итератор переходит в инвалидное состояние: все его указатели становятся =0, а atend(от него) ==true
уменьшается счетчик итераторов на предыдущем буфере
и увеличивается счетчик итераторов на следующем буфере
если предыдущий буфер был последним слева
проверяется его счетчик итераторов
и если он==0 - буфер удаляется

при создании итератора по умолчанию - его состояние инвалидное
при копировании/деструктировании - изменяются и проверяются счетчики итераторов на буферах

перед деструктированием всего потока на нем не должно оставаться валидных итераторов
поток не имеет ссылок на итераторы, а если поток удален и после этого происходит удаление итератора - обязательно произойдет обращение к уже удаленному потоку
если такое произошло, поток конечно все удалит, но потом все равно бросит исключение

копирование итераторов - операция по эффективности терпимая
!но лучше ее использование минимизировать!

---
я бы сделал так:
сразу после конструирования поток не загружает ничего
а загружает только при первом обращении, чтобы получить первый итератор
а это обращение будет методом c_str(), для одинаковости со строками
---
если вдруг несколько тредов будет работать с одним файлом
нужно обеспечить неподвижность копируемых итераторов
и чтобы ++ и -- счетчиков итераторов работали по очереди
ну и чтоб сами буфера в одном и том же месте изменялись по очереди
*/

**если буфера фиксированного размера - это называется блочная буферизация
также в буфера можно загружать отдельно строки - это называется строчная буферизация
?!существуют ли функции ОС, позволяющие загружать не блоки фикс. размера а строки, заканчивающиеся опр. символом????!!!!!
и для stdin'а подойдет только строковая, т.к. если блок большой, а он обычно порядка нескольких килобайт /*лучше всего, если совпадает с размером кластера на диске*/, то процесс чтения блока не отдаст управление пока не получит из консоли все символы, необходимые для заполнения блока.

кстати можно изменять/отключать тип буферизации в FILE
но там буферизуется только 1 блок или строка
-----------------

теперь классифицируем потоки
(чтобы исправить некоторую путаницу, которую вносит идеология юникс)
есть последовательные потоки, это stdin, stdout, все связанное с сетью, данные, генерируемые процессами
и случайного доступа - файлы
файлы можно читать писать и делать и то и другое одновременно, как с обычными массивами, и вообще, это отдельные функции, каждую из которых можно использовать, а можно не использовать
а последовательные - либо к вам либо от вас, либо input либо output
будем их  называть
ввода
вывода
файловый (произвольного доступа - это долго, но это будет синонимом)

...картинки...

расширяющие итераторы
- отличаются от итераторов, описанных выше
тем, что при их перемещении за границу файла эта граница файла переместиться вместе с ними
таким образом перед закрытием потока надо специально все такие итераторы отвязать от него
если поток позволяет его изменять - его можно изменять и нерасшитяющими итераторами

потоки, как расширяющие итераторы
было бы удобно сделать, чтобы у идентификаторов самих потоков был бы такой же интерфейс, как и у расширяющих итераторов
(с тем лишь отличием, что им нельзя присваивать другие итераторы)

ввода
с правого конца считывает информацию из файла, как только туда дошли итераторы
как только файл кончился - итераторы начинают упираться в конец файла
с левого конца, как только итераторы от туда ушли, он забывает данные
итераторы могут как читать, так и писать в буфер

вывода
с левого конца, как только итераторы от туда ушли, записывает инф-у в файл
с правого конца есть полузаполненный буфер, правая граница которого
является концом файла для обычных итераторов
новый незаполненный буфер может открыть только расширяющий итератор
можно вызвать поток.флаш([р_]итератор), и тогда все до этого итератора запишется в файл, если конечно на предыдущих буферах не находятся другие итераторы, что вызовет ошибку.
а если на предыдущих буферах нет итераторов, то нет и этих буферов
т.е. буфер, на котором этот [р_]итератор должен быть последним
буфера должны еще иметь указатель, откуда записывать в файл дальше
итераторы, находящиеся в том же буфере, но левее этого [р_]итератора
ничего страшного не представляют, все что они сделают левее (откуда записывать в файл) - все равно потеряется
главное, чтобы пока они будут левее откуда записывать в файл не вызвался флаш от них
в таком потоке всегда имеется один встроенный р_итератор, который всегда находится на последнем справа буфере
если появился новый буфер, и встроенный р_итератор находится не на нем, то он перемещается в начало этого буфера
паред закрытием потока надо установить встроенный р_итератор на ту позицию, где конец файла. это можно сделать при помощи поток.флаш([р_]итератор)
...

файловые
это смесь двух предыдущих
только р_итераторы ведут себя как обычные итераторы до тех пор, пока не будет прочитан конец файла
+перед каждым чтением/записью происходит fsetpos
-----------------

ограничение на алгоритмы
во всех алгоритмах СТЛ итераторы передаются по значению
и в промежуточных функциях, которые необходимы для определения некоторых параметров шаблонов, они сохраняются
и если мы прменяем алгоритм ко всему файлу, 
эти сохраняющиеся итераторы не дадут потокам выгружать из памяти уже не используемые участки файлов.
(конечно inline подстановка может и решит это, но ключевое слово здесь "может")
вывод:
по возможности, надо передавать итераторы либо по указателям, либо по ссылкам
/*
наверно, когда-нибудь заебавшись писать звездочки я начну использовать передачу по ссылке
а может и нормально будет - попрактиковаться нужно
*/
-----------------------

специализация алгоритмов, базовые алгоритмы
<string.h> и char_traits существуют не просто так
а потому, что в ассемблере (по крайннй мере x86) существуют строковые операции
которые выполняются бысрее, нежели их аналоги, раписанные просто на си
чтобы реализовать тоже самое в шаблонных алгоритмах
мы выделим несколько базовых алгоритмов, и специализируем их для каждых типов итераторов и соответствующих им строках/потоках
/*
остается их выделить
просто скопировать их из string.h - не самая лучшая идея
т.к. большинство из них возвращает не всю вычисленную информацию
+избавимся от коллизии имен
в общем нужно эксперементировать
*/
------------------------

алгоритмы печати, локаль
на основе базовых алгоритмов будут построены:
- алгоритмы парсинга, по типу тех, о которых я говорил в самом начале
	для разбора строк, чисел, и прочих вещей, которые можно считать общими и базовыми
- алгоритмы печати (которые печатают)
мне не нравится, как это реализовано в стандартной библиотеке си++:
выводишь объект, и надо вспоминать, какого же он типа (например символ это или число)
как бы нарушаются базовые сишные принципы
хочется как-то так:
итератор._тип_(значение)._тип_(значение)...
где _тип_ - идентификатор, по которому можно понять, каким типом будет выведено значение /*можно например dec hex oct ch str, но тут много вариантов для креатива...*/
но, т.к. в си++ нельзя определять методы вне класса, а наследование здесь не подойдет (т.к. ранее определенные методы не могут возвращать тип, содержащий методы, определенные позднее;
нет конечно могут (хотя проверить надо), но все равно придется определять это макросом, значение которого придется каждый раз менять при определении новой функции; кароче это не вариант)
а вот операторы вне класса (как это как раз и сделано в стд библиотеке) переопределять можно
может быть когда-нибудь и добавят в си++ operator.(...)
но пока это предлагается решать так:
inline some_unique_type _тип_(...); //some_unique_type содержит данные, переданные в _тип_(...)
template<class Tit>
Tit & operator<<(Tit&,some_unique_type);//Tit - произвольный (желательно расширяющий) итератор
таким образом можно писать
it<<_тип_(...)
/*
конечно это жудко не эффективно, но надо посмотреть, как это будет компилироваться с инлайном
кстати вот интересно, что быстрее:
парсить строку формата, и доставать оттуда параметры вывода
или передавать эти параметры как аргументы функции через стек
?
*/
/*
для вычисления, сколько мест заполнено в результате той или иной ф-ции
можно запомнить предыдущий итератор, а потом вычислить разность текущего и запомненного
и даже перезаписать это место, т.к. в файл не ушло ничего, что правее самого левого итератора
или обрезать выведенное справа, просто поставив итератор для дальнейшего вывода в то место откуда надо отрезать
для обрезания слева надо будет скопировать выведенное левее
*/

теперь про локаль:
в стандартной библиотеке файлы содержат информацию, определяющую локаль
итераторы не могут содержать такую информацию, и ее придется передавать в дополнительных аргументах функций _тип_(...)

для совместимости можно будет определить обертку итераторов, содержащую информацию о локали (наверно ее надо будет наследовать от соотв. базовых абстрактных классов стандартной библиотеки)
---------------------

дополнительные фишки:
(чего хочется добавить еще)

перекодировка
из файла загружается блок, перекодируется, и так и остается в буфере
перед выгрузкой перекодируется обратно и выгружается

/*
можно взять юникодную таблицу за основу, и для каждой кодовой таблицы записать массив (размером 256 символов) где каждый символ - его номер в юникодной таблице
и при перекодировке из одной кодировки в другую динамически создается массив перекодировки на основе массивов каждой из кодировок, который содержит коды соотв. символов в другой кодировке или например знаки '?', если такого символа в другой кодировке нет

но это перекодировка байт в байт
*/

многобайтная перекодировка
в си даже есть специальное понятие mbchar mbstring и соотв. функции для работы с ними, а в реальной жмзни это utf8, и примечательно оно тем, что разные стмволы могут иметь разную длину в байтах
я к многобайтной перекодировке отношу также концы строк в windows & macos

здесь усложняется загрузка и выгрузка блоков, а если это файл произвольного доступа, 
во первых может захотеться иметь несколько обласей загруженных в память с которыми работаешь, с промежутками, выгруженными из памяти
но здесь лучше к одному файлу подключить несколько потоков
!произвольный доступ разбивается на файл и потоки
(и еще остается не запутаться, чтоб эти потоки не перкрывались)
! и голова и хвост каждого потока должны помнить позицию в файле
+должен быть способ обрезать файл

возвращение типа ошибок
хочется, чтобы парсящие функции возвращали не просто bool
а что-то, что может конвертироваться в bool, и при этом содержащее
если не удалось распарсить
сообщение, например, что ожидалось
и позицию в файле, где произошла неудача
но тут возникают сложности с позицией - ее надо будет определять по итератору
ее можно представлять как абсолютную позицию в файле, и как №строки №столбца
и так, эта позиция будет в символах (размер которых может меняться при многобайтовой перекодировке)
при блочной буферизации это будут символы от начала файла
при строковой буферизации это будет строка-столбец

превращение итератора по файлу в адрес по файлу, и обратно
 - чтобы при повторном проходе по файлу можно было попасть сразу в нужную точку
это имеет смысл, только если файл не подвергается изменениям
и только если перед перемещением к следующей точке все итераторы, работающие в области предыдущей точки, стали инвалидными
при отсутсвии многобайтовой перекодировки проблем нет никаких
при присутствии:
для получения адреса - каждый буфер будет хранить адрес в файле своего начала
и будет иметься функция, осуществляющая обратное преобразование, и сопоставляющая смещение в буфере соответствующему смещению в файле
а у потоков по файлам будет спец. возможность стартовать поток с опр. позиции
если буферизация строчная, а идет только преобразование концов строк, 
то такая функция даже не будет осущетсявлять никакого обратного преобразования

--------
!итого получается 6 потоков:
3 со строковой буферизацией
и 3 с блочной
все предоставляют внешне многобайтовую перекодировку (функциями), а внутренни - однобайтовую (таблицами)
все блочные потоки содержат номера символов от начала
а все строковые - строку-столбец от начала
+возможность установить их нач.значения
адреса в файле начал буферов
функцию, преобразующую смещение в буфере в смещение в файле
+файловые - перед чтением/записью делают fsetpos

остается разобраться с константностью

+возможность менять это на лету
*строковая/блочная буферизация
*размер блока/максимальный строки
*спрашивать ли fgetpos или вычислять самому//для изменеия всегда тру
?при многобайтовой перекодировке может быть оставлять исходный буфер
ввода
ф-ция многобайтовой перекодировки(см mb аналоги в си)
таблица/вектор однобайтовой перекодировки
ф-ция вычисления смещения
константный - нельзя писать
вывода
ф-ция многобайтовой перекодировки
таблица/вектор однобайтовой перекодировки
ф-ция вычисления смещения(может использовать предыд таблицу и функцию)
константный - бред
ввода-вывода
2 ф-ции многобайтовой перекодировки
2 таблицы/вектора однобайтовой перекодировки
ф-ция вычисления смещения(может использовать предыд таблицу и функцию)
константный - нельзя писать - бред
/*
обычно ввода-вывода можно заменить на 1 проход чтения
и 1 проход с установками в нужные места - записью
*/

---------
базовый разбор лексем
допустим мы решили написать компилятор си (еще один)
каджый раз считывать идннтификатор, и проверять, например, не является ли он каким нибудь ключевым словом, - не эффективно
по этому перед синтаксическим анализом проводят лексический, разбирающий более мелкие конструкции единожды, и сохраняющий их
и для такого можно сделать отдельный промежуточный поток
который своими элементами имеет лексемы (они же токены)
он будет поверх обычного потока разбирать из него символы и формировать токены
а уже набор функций синтаксического анализатора будет разбирать последовательности токенов на всякие выражения, блоки, функции...
типы токенов:
идентификаторы/ключевые слова
числовые, символьные, строковые литералы (т.е. значения, встречающиеся в коде)
скобки и знаки операторов






todo
определиться с возможностями потоков
просмотреть имеющийся код
вспомнить разбиение на файлы
определиться с базовыми алгоритмами, и закодить их, и спецализировать для строк
закодить потоки ввода и вывода
покумекать над общими алгоритмами
определиться и закодить базовые алгоритмы вывода
что-нибудь распарсить и при этом определиться с базовыми и небазовыми алгоритмами парсинга
подумать, как изменить или написать заново контейнер для строк
специализировать базовые алгоритмы для имеющихся потоков и контейнера строк
если вдруг возникнет необходимость - написать изменяющий поток, и специализировать для него базовые алгоритмы




